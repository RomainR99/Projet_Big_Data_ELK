## 1) Cr√©er l'index airbnb-listings avec ton mapping (Kibana ‚Üí Dev Tools)

‚ö†Ô∏è Si l'index existe d√©j√†, supprime-le d'abord : `DELETE airbnb-listings`

```json
PUT airbnb-listings
{
  "mappings": {
    "properties": {
      "id": { "type": "keyword" },
      "name": { "type": "text" },
      "host_id": { "type": "keyword" },
      "host_is_superhost": { "type": "keyword" },
      "neighbourhood_cleansed": { "type": "keyword" },
      "room_type": { "type": "keyword" },
      "target_city": { "type": "keyword" },
      "price": { "type": "float" },
      "review_scores_rating": { "type": "float" },
      "accommodates": { "type": "integer" },
      "bedrooms": { "type": "integer" },
      "beds": { "type": "integer" },
      "number_of_reviews": { "type": "integer" },
      "minimum_nights": { "type": "integer" },
      "location": { "type": "geo_point" }
    }
  }
}
```

## 2) Script 1 ‚Äî 1_clean_data.py (fusion + nettoyage ‚Üí Parquet)

Cr√©e un fichier `1_clean_data.py`.

### Lancer le nettoyage

```bash
python3 1_clean_data.py \
  --bangkok ./listings_bangkok.csv \
  --barcelona ./listings_barcelona.csv \
  --out ./airbnb_clean.parquet
```

**D√©pendances :** `python3 -m pip install pandas pyarrow`

```bash
romain@MacBook-Air-de-Romain mon projet % python3 1_clean_data.py \
  --bangkok ./listings_bangkok.csv \
  --barcelona ./listings_barcelona.csv \
  --out ./airbnb_clean.parquet
[OK] Export parquet: airbnb_clean.parquet
[STATS] rows=48216
[STATS] missing_price=9667 (20.05%)
[STATS] missing_location=0 (0.00%)
```

## 3) Script 2 ‚Äî 2_send_to_elk.py (Parquet ‚Üí Elasticsearch / Bulk)

Cr√©e un fichier `2_send_to_elk.py`.

### Lancer l'injection

```bash
python3 -m pip install elasticsearch
python3 2_send_to_elk.py --parquet ./airbnb_clean.parquet --index airbnb-listings
```

```bash
romain@MacBook-Air-de-Romain mon projet % python3 -m pip install elasticsearch
python3 2_send_to_elk.py --parquet ./airbnb_clean.parquet --index airbnb-listings

Requirement already satisfied: elasticsearch in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (8.19.3)
Requirement already satisfied: elastic-transport<9,>=8.15.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from elasticsearch) (8.17.1)
Requirement already satisfied: python-dateutil in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from elasticsearch) (2.9.0.post0)
Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from elasticsearch) (4.15.0)
Requirement already satisfied: urllib3<3,>=1.26.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2.6.2)
Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2026.1.4)
Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil->elasticsearch) (1.17.0)

[notice] A new release of pip is available: 24.3.1 -> 25.3
[notice] To update, run: pip3.12 install --upgrade pip
[OK] Connect√© √† Elasticsearch: es-node-1 / 8.11.1
/Users/romain/Desktop/Big Data/mon projet/2_send_to_elk.py:54: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.
  for ok, item in helpers.streaming_bulk(
[OK] Bulk termin√© -> index=airbnb-listings
[STATS] sent=48216 failures=0 (voir bulk_failures.jsonl)
[VERIFY] GET airbnb-listings/_count -> 48216
```

### V√©rification dans Kibana

```json
GET airbnb-listings/_count
```

```json
{
  "count": 48216,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  }
}
```

Parfait ‚úÖ Tout est coh√©rent :

- `sent=48216`
- `_count=48216` dans Kibana

√áa prouve que :

- tes deux CSV ont bien √©t√© fusionn√©s
- la colonne `target_city` a √©t√© ajout√©e
- l'indexation Bulk a fonctionn√© sans erreurs (`failures=0`)
- aucun √©crasement de documents (pas de `_id` forc√©)

## Validation de l'ingestion (ETL ‚Üí Elasticsearch)

L'ingestion des donn√©es nettoy√©es a √©t√© r√©alis√©e via un script Python utilisant l'API Bulk (`helpers.streaming_bulk`).
Le script indexe les documents dans l'index **`airbnb-listings`**.

### R√©sultat d'ex√©cution du script (preuve)

```text
[STATS] sent=48216 failures=0 (voir bulk_failures.jsonl)
[VERIFY] GET airbnb-listings/_count -> 48216
```

**Conclusion :**

- Le nombre de documents envoy√©s (`sent`) correspond au nombre de documents pr√©sents dans Elasticsearch (`_count`).
- Aucune erreur d'indexation n'a √©t√© d√©tect√©e (`failures=0`).
- L'ingestion est donc compl√®te et fiable.

### V√©rification de la pr√©sence des 2 villes (target_city)

```json
GET airbnb-listings/_search
```
```json
{
  "size": 0,
  "aggs": {
    "by_city": {
      "terms": {
        "field": "target_city",
        "size": 10
      }
    }
  }
}
```

```json
{
  "took": 80,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 10000,
      "relation": "gte"
    },
    "max_score": null,
    "hits": []
  },
  "aggregations": {
    "by_city": {
      "doc_count_error_upper_bound": 0,
      "sum_other_doc_count": 0,
      "buckets": [
        {
          "key": "bangkok",
          "doc_count": 28806
        },
        {
          "key": "barcelona",
          "doc_count": 19410
        }
      ]
    }
  }
}
```

**Interpr√©tation :**

- Les deux valeurs `bangkok` et `barcelona` sont bien pr√©sentes.
- Chaque document est correctement tagu√© via la colonne `target_city`.
- La fusion des deux fichiers CSV a donc √©t√© r√©alis√©e avec succ√®s.


## Ce script enl√®ve bien le $ (et aussi les ,) du prix et convertit en float

### Pourquoi c'est garanti dans ton code

Dans `clean_price_to_float()` :

- `s.str.replace(",", "", regex=False)` ‚ûú enl√®ve les virgules (s√©parateurs de milliers)
- `PRICE_CLEAN_RE = re.compile(r"[^\d\.\-]")` ‚ûú enl√®ve tout ce qui n'est pas chiffre / point / signe -
  üëâ donc `$`, espaces, lettres, etc. disparaissent
- `pd.to_numeric(...).astype("float64")` ‚ûú conversion en nombre d√©cimal

**Donc :**

`"$1,416.00"` ‚Üí `"1416.00"` ‚Üí `1416.0`

## Bonus

### Etape 1 : D√©veloppement du Script NLP

**R√¥le :** Data Scientist

Vous devez d√©velopper un script Python nomm√© `3_analyze_reviews.py`. Ce script sera responsable de l'enrichissement de la donn√©e.

**Pr√©-requis techniques :**

- Librairie : TextBlob (pour l'analyse de sentiment).
- Fichier source : `reviews.csv` (contient les commentaires).

**Sp√©cifications du script :**

1. Lecture du fichier CSV par paquets (chunks) pour g√©rer le volume important de donn√©es.
2. Nettoyage basique des commentaires (suppression des lignes vides).
3. Calcul du "Score de Polarit√©" pour chaque commentaire via TextBlob :
   - Le score va de -1.0 (Tr√®s n√©gatif) √† +1.0 (Tr√®s positif).
4. Cr√©ation d'un "Label" bas√© sur le score :
   - Si score < 0 : Label = "Negatif"
   - Si score > 0 : Label = "Positif"
   - Sinon : Label = "Neutre"
5. Envoi des documents enrichis vers un nouvel index Elasticsearch nomm√© `airbnb-reviews`.

**D√©pendances :** `python3 -m pip install pandas elasticsearch textblob`
(et si besoin : `python3 -m textblob.download_corpora`)

### 3_analyze_reviews.py

```bash
python3 3_analyze_reviews.py \
  --bangkok ./reviews_bangkok.csv \
  --barcelona ./reviews_barcelona.csv \
  --es http://localhost:9200 \
  --index airbnb-reviews
```

**Estimation du temps de traitement (machine locale type MacBook)**

| Volume reviews | Temps estim√© |
|----------------|--------------|
| ~10 000        | 15‚Äì30 s      |
| ~25 000        | 30‚Äì90 s      |
| ~50 000        | 1‚Äì2 min      |
| ~100 000       | 3‚Äì5 min      |

Le temps de traitement est domin√© par l'analyse NLP, r√©alis√©e commentaire par commentaire.
Gr√¢ce au traitement par paquets et √† l'indexation Bulk, le pipeline reste performant et scalable,
avec un temps d'ex√©cution de l'ordre de la minute pour plusieurs dizaines de milliers de commentaires.

```text
[INFO] barcelona chunk 204: processed_rows=4270 total_indexed=1019160 failures=0

[OK] NLP + Bulk termin√©
[STATS] indexed=1602423 failures=0 empty_or_blank_rows_skipped=180
[VERIFY] GET airbnb-reviews/_count -> 1602423
[LOG] failures -> reviews_bulk_failures.jsonl
```

**Comment acc√©l√©rer ?**

- Parall√©lisation (multiprocessing)
- Mod√®les plus rapides (VADER, spaCy)
- Offload vers cluster Spark NLP
- Batch inference

**Une barre de progression dans le script :**

```bash
python3 -m pip install tqdm
```

Ajoute l'import en haut : `from tqdm import tqdm`

## NLP ‚Äì Ingestion et enrichissement des avis (TextBlob ‚Üí Elasticsearch)

### Objectif

Analyser les commentaires du fichier `reviews` afin de transformer du texte libre en indicateurs quantifiables :

- **score de polarit√©** (TextBlob) : -1 (tr√®s n√©gatif) ‚Üí +1 (tr√®s positif)
- **label** d√©riv√© : `Negatif`, `Neutre`, `Positif`

Les donn√©es enrichies sont index√©es dans un nouvel index Elasticsearch : **`airbnb-reviews`**.

### R√©sultat d'ex√©cution (preuve)

```text
[OK] NLP + Bulk termin√©
[STATS] indexed=1602423 failures=0 empty_or_blank_rows_skipped=180
[VERIFY] GET airbnb-reviews/_count -> 1602423
[LOG] failures -> reviews_bulk_failures.jsonl
```

1 602 423 reviews index√©es, 0 √©chec, seulement 180 lignes vides ignor√©es.

### V√©rifications Kibana (Dev Tools)

#### 1) V√©rifier la volum√©trie

```json
GET airbnb-reviews/_count
```
```json
{
  "count": 1602423,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  }
}
```

Le compte est bon.

## Bonus

### Etape 2 : Configuration de l'Index (Mapping)

**R√¥le :** Elasticsearch Engineer

Le texte des commentaires est long et complexe. Il n√©cessite un mapping adapt√© pour permettre √† la fois la recherche de phrases et l'analyse de mots-cl√©s.

**Action dans Dev Tools :**

Cr√©er l'index `airbnb-reviews` avec les propri√©t√©s suivantes :

- `listing_id` : keyword (pour faire la jointure mentale avec les annonces).
- `date` : date.
- `reviewer_name` : text.
- `comments` : text (activ√© pour la recherche plein texte).
- `sentiment_score` : float.
- `sentiment_label` : keyword (pour les filtres et camemberts).

### Cr√©ation de l'index avec mapping adapt√©

Supprimer l'index existant : `DELETE airbnb-reviews`

Recr√©er l'index avec le mapping demand√© :

```json
PUT airbnb-reviews
```
```json
{
  "mappings": {
    "properties": {
      "listing_id": {
        "type": "keyword"
      },
      "date": {
        "type": "date"
      },
      "reviewer_name": {
        "type": "text"
      },
      "comments": {
        "type": "text"
      },
      "sentiment_score": {
        "type": "float"
      },
      "sentiment_label": {
        "type": "keyword"
      }
    }
  }
}
```

### Relancer le script NLP

```bash
python3 3_analyze_reviews.py \
  --bangkok ./reviews_bangkok.csv \
  --barcelona ./reviews_barcelona.csv \
  --es http://localhost:9200 \
  --index airbnb-reviews
```

Ou alors `PUT airbnb-reviews-v2` et :

```bash
python3 3_analyze_reviews.py \
  --bangkok ./reviews_bangkok.csv \
  --barcelona ./reviews_barcelona.csv \
  --index airbnb-reviews-v2
```

### üîπ C'est quoi un script NLP ?

Un script NLP (Natural Language Processing / Traitement du Langage Naturel) est un programme qui analyse du texte √©crit par des humains pour en extraire des informations exploitables par une machine.

Contrairement aux chiffres (prix, notes), le texte est :

- non structur√©
- subjectif
- ambigu

Le NLP sert √† transformer ce texte libre en donn√©es mesurables.

**Enrichit la donn√©e**

**Avant :**

```
"Very noisy apartment, couldn't sleep"
```

**Apr√®s NLP :**

```json
{
  "comments": "Very noisy apartment, couldn't sleep",
  "sentiment_score": -0.62,
  "sentiment_label": "Negatif"
}
```

**Pourquoi c'est important pour un investisseur ?**

Parce que :

- une note moyenne peut masquer des probl√®mes r√©currents
- le NLP d√©tecte des signaux faibles (bruit, propret√©, humidit√©, s√©curit√©)

Un script NLP est un programme qui transforme du texte libre en indicateurs quantifiables afin de permettre une analyse automatique de la satisfaction et des risques non visibles dans les donn√©es chiffr√©es.

**Version "Data Scientist" :**

Le script NLP applique des techniques de traitement du langage naturel afin d'extraire un score de sentiment √† partir des commentaires utilisateurs.
Il permet d'enrichir les donn√©es structur√©es par une dimension qualitative exploitable pour l'analyse d√©cisionnelle. 

#### 1Ô∏è‚É£ Le probl√®me √† r√©soudre est simple

On cherche √† savoir :

- si un avis est globalement positif, neutre ou n√©gatif
- pas √† comprendre des nuances linguistiques complexes

**Exemples :**

- `"Very noisy at night"` ‚Üí n√©gatif
- `"Clean and well located"` ‚Üí positif

TextBlob fait cela correctement.

#### 2Ô∏è‚É£ TextBlob est rapide et l√©ger

- Pas d'entra√Ænement
- Pas de GPU
- Pas de d√©pendances lourdes
- Fonctionne en local

**Dans ton cas :**

- 1,6 million de commentaires analys√©s
- Temps de traitement ma√Ætris√© (quelques minutes)

**TextBlob permet :**

- des agr√©gations globales (taux de n√©gatif par ville)
- des comparaisons (Bangkok vs Barcelona)
- des dashboards Kibana exploitables

üëâ C'est exactement ce qu'un investisseur attend en premier niveau.

TextBlob est suffisant dans ce contexte car l'objectif est une analyse de sentiment globale √† grande √©chelle.
Il offre un excellent compromis entre simplicit√©, performance et valeur analytique, sans complexit√© inutile.

On v√©rifie que le mapping est exact :

```json
GET airbnb-reviews/_mapping
```
```json
{
  "airbnb-reviews": {
    "mappings": {
      "properties": {
        "comments": {
          "type": "text"
        },
        "date": {
          "type": "date"
        },
        "listing_id": {
          "type": "keyword"
        },
        "review_id": {
          "type": "text",
          "fields": {
            "keyword": {
              "type": "keyword",
              "ignore_above": 256
            }
          }
        },
        "reviewer_id": {
          "type": "text",
          "fields": {
            "keyword": {
              "type": "keyword",
              "ignore_above": 256
            }
          }
        },
        "reviewer_name": {
          "type": "text"
        },
        "sentiment_label": {
          "type": "keyword"
        },
        "sentiment_polarity": {
          "type": "float"
        },
        "sentiment_score": {
          "type": "float"
        },
        "target_city": {
          "type": "text",
          "fields": {
            "keyword": {
              "type": "keyword",
              "ignore_above": 256
            }
          }
        }
      }
    }
  }
}
```

**Preuve que √ßa fonctionne :**

```json
GET airbnb-reviews/_search
```
```json
{
  "size": 5,
  "query": {
    "match": {
      "comments": "noise"
    }
  },
  "_source": ["comments", "sentiment_score", "sentiment_label"]
}
```

```json
{
  "took": 147,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 10000,
      "relation": "gte"
    },
    "max_score": 7.7285895,
    "hits": [
      {
        "_index": "airbnb-reviews",
        "_id": "ws0tmZsBPhNOaOkLQTit",
        "_score": 7.7285895,
        "_source": {
          "comments": "Noise noise noise during the day! Bad experience in a great apt",
          "sentiment_label": "Positif"
        }
      },
      {
        "_index": "airbnb-reviews",
        "_id": "ecUqmZsBPhNOaOkLxrYo",
        "_score": 7.6836963,
        "_source": {
          "comments": "Street traffic noise, waterpipe noise and ac noise made it difficult to sleep.",
          "sentiment_label": "Negatif"
        }
      },
      {
        "_index": "airbnb-reviews",
        "_id": "0L8omZsBPhNOaOkLqwgq",
        "_score": 7.0590267,
        "_source": {
          "comments": "everythingis OK„ÄÇ but it's very noise because it located at cross road. very noise!",
          "sentiment_label": "Positif"
        }
      },
      {
        "_index": "airbnb-reviews",
        "_id": "FdMvmZsBPhNOaOkLTiSc",
        "_score": 6.947796,
        "_source": {
          "comments": "Nice hotel, friendly staff. No outside noise but could hear a lot of noise from inside.",
          "sentiment_label": "Positif"
        }
      },
      {
        "_index": "airbnb-reviews",
        "_id": "ttQvmZsBPhNOaOkL20h7",
        "_score": 6.893484,
        "_source": {
          "comments": "To much noise and never all time distrub . I am hole night not sleeping . Too much noise‚Ä¶",
          "sentiment_label": "Positif"
        }
      }
    ]
  }
}
```

```json
GET airbnb-reviews/_search
```
```json
{
  "size": 0,
  "aggs": {
    "score_stats": {
      "stats": {
        "field": "sentiment_score"
      }
    }
  }
}
```

```json
{
  "took": 70,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 10000,
      "relation": "gte"
    },
    "max_score": null,
    "hits": []
  },
  "aggregations": {
    "score_stats": {
      "count": 0,
      "min": null,
      "max": null,
      "avg": null,
      "sum": 0
    }
  }
}
```

## Bonus

### Etape 3 : Visualisation Textuelle (Tag Cloud)

**R√¥le :** Data Analyst

Il est impossible de lire 50 000 commentaires. Vous devez synth√©tiser les sujets de plainte r√©currents.

**Objectif :**

Cr√©er une visualisation de type "Tag Cloud" (Nuage de Mots) dans Kibana.

**Configuration :**

1. Source de donn√©es : Index `airbnb-reviews`.
2. M√©trique : Count (Nombre d'apparitions).
3. Bucket (Termes) : Champ `comments`.
4. Filtre obligatoire : Filtrer uniquement les documents o√π `sentiment_label` est √©gal √† `Negatif`.
5. Exclusion : Exclure les mots de liaison courants (stopwords) comme "the", "and", "a", "to", "was".

**Question m√©tier √† r√©soudre :**

Quels sont les 5 mots qui reviennent le plus souvent dans les avis n√©gatifs ? (Exemple attendu : noise, dirty, small, stairs, cold).

Lens, Maps, TSVB, Custom visualisation

**Management**

- Ingest
  - Ingest Pipelines
- Data
  - Index Management
  - Index Lifecycle Policies
  - Snapshot and Restore
  - Rollup Jobs
  - Transforms
  - Remote Clusters
- Migrate
- Alerts and Insights
  - Rules
  - Cases
  - Connectors
  - Reporting
- Machine Learning
- Maintenance Windows

**Kibana**

- Data Views
- Files
- Saved Objects
- Tags
- Search Sessions
- Spaces
- Advanced Settings

**Stack**

- License Management
- Upgrade Assistant

### Pourquoi Lens ?

Parce que :

- tu veux faire un Tag Cloud (nuage de mots),
- √† partir d'un champ texte (`comments`),
- avec un filtre m√©tier (`sentiment_label = Negatif`),
- sans code, sans complexit√©.

```json
GET airbnb-reviews/_mapping/field/comments
{
  "airbnb-reviews": {
    "mappings": {
      "comments": {
        "full_name": "comments",
        "mapping": {
          "comments": {
            "type": "text"
          }
        }
      }
    }
  }
}
```

Le champ `comments` est bon.

## Visualisation Tag Cloud dans Kibana

### Cr√©ation de la vue

![Cr√©ation de la vue](./images/cr√©ation_de_la_vue.png)

### Le champ comments n'est pas l√†

![Le champ comments n'est pas l√†](./images/le_champ_comments_n_est_pas_la.png)

### Le champ est bien dans comments

![Le champ est bien dans comments](./images/le_champ_est_bien_dans_comments.png)

### Lens

![Lens](./images/lens.png)

### Tag Cloud

![Tag Cloud](./images/tag_cloud.png)